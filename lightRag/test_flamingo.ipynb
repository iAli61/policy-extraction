{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0ad64897-baa9-4d49-80b1-7b5ba477eafd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# !pip install -q openai==1.30.1\n",
    "# !pip install -q  msal==1.28.0\n",
    "# !pip install -q httpx==0.27.0\n",
    "# !pip install -q dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b52d613-10f9-41ac-ae92-f7e78c2be2bd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d623804-10c6-403e-ac1e-3b2fb08a7d46",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from flamingo_client import FlamingoLLMClient\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "697f3bda-944d-43a6-ab89-ad8de311b5f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "client = FlamingoLLMClient(\n",
    "            subscription_id=os.getenv(\"SUBSCRIPTION_ID\"),\n",
    "            base_url=os.getenv(\"BASE_URL\"),\n",
    "            client_id=os.getenv(\"CLIENT_ID\"),\n",
    "            client_secret=os.getenv(\"CLIENT_SECRET\"),\n",
    "            subscription_key=os.getenv(\"SUBSCRIPTION_KEY\"),\n",
    "            tenant=os.getenv(\"TENANT_ID\")\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4cc5ba30-c9eb-40f8-937b-c2c7a27bb883",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def initialize_llm_client():\n",
    "    \"\"\"\n",
    "    Initializes the FlamingoLLMClient with required credentials.\n",
    " \n",
    "    Returns:\n",
    "        FlamingoLLMClient: The initialized FlamingoLLMClient instance.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client = FlamingoLLMClient(\n",
    "            subscription_id=os.getenv(\"SUBSCRIPTION_ID\"),\n",
    "            base_url=os.getenv(\"BASE_URL\"),\n",
    "            client_id=os.getenv(\"CLIENT_ID\"),\n",
    "            client_secret=os.getenv(\"CLIENT_SECRET\"),\n",
    "            subscription_key=os.getenv(\"SUBSCRIPTION_KEY\"),\n",
    "            tenant=os.getenv(\"TENANT_ID\")\n",
    "        )\n",
    "        return client\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Error initializing Flamingo LLM client: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5bea9536-9004-4994-ba7c-9ccf702bcb0e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def process_with_llm(prompt, client,temperature=0.1):\n",
    " \n",
    "    try:\n",
    " \n",
    "        # Define the system message with a focus on general understanding and context extraction\n",
    " \n",
    "        system_message = (\n",
    "            \"When asked about 'Who is insured', extract the result for 'who is insured, reinsured or additional insured'\"\n",
    " \n",
    "            \"You are a claims processing assistant with access to context regarding insurance claims. \"\n",
    " \n",
    "            \"You can respond only using the information provided in the context. \"\n",
    " \n",
    "            \"When a question asks for specific entities, like 'who is insured?', try to extract that information. \"\n",
    " \n",
    "            \"If the required information is not available in the context, inform the user accordingly.\"\n",
    "         \n",
    " \n",
    "        )\n",
    " \n",
    "        # Construct the prompt dynamically\n",
    " \n",
    "        messages = [\n",
    " \n",
    "            {\"role\": \"system\", \"content\": system_message},\n",
    " \n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    " \n",
    "        ]\n",
    " \n",
    "        # Send the request to LLM with the dynamic prompt\n",
    " \n",
    "        response = client.chat.completions.create(\n",
    " \n",
    "            model=\"llama3\",  # You may use a more suitable model if available\n",
    " \n",
    "            temperature = temperature,\n",
    "            messages=messages,\n",
    " \n",
    "            stream=False,\n",
    " \n",
    "        )\n",
    " \n",
    "        # Extract the response content\n",
    " \n",
    "        answer = response.choices[0].message.content.strip()\n",
    " \n",
    "        # Debugging: Print the full response for troubleshooting\n",
    " \n",
    "        print(\"üîç Full LLM Response:\", response)\n",
    " \n",
    "        return answer if answer else \"No relevant information found in the context.\"\n",
    " \n",
    "    except Exception as e:\n",
    " \n",
    "        print(f\"‚ùå Error processing with LLM: {e}\")\n",
    " \n",
    "        return \"An error occurred while generating the response\"\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a1ad71b0-12f9-4525-b4ec-5bb2c5688b85",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "llm_client = initialize_llm_client()\n",
    "print(\"‚úÖ LLM Client Initialized:\", llm_client)  # Debugging: Verify client is initialized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "613afbc5-7686-4536-a067-5b3daa04f689",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "process_with_llm(\"Hi\", llm_client,temperature=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "38ef4ae1-9a44-4336-a435-9863782a47e2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "test_flamingo",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
